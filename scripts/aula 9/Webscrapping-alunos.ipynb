{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc4bbd8",
   "metadata": {},
   "source": [
    "# Construção de dados\n",
    "\n",
    "## Coletando dados\n",
    "\n",
    "Muitas vezes, nosso dado de interesse não está imediatamente disponível e é necessário coletá-lo. Esse processo geralmente é realizado por engenheiros de dados, mas em equipes reduzidas é comum que esse trabalho fique para o analista de dados.\n",
    "\n",
    "Existem várias formas de coletar dados e vamos focar na técnica de raspagem de dados ou Web Scrapping. Essa técnica corresponde a coletar os dados diretamente da Web através de bibliotecas que lerão páginas HTML e vão retirar os dados de lá. \n",
    "\n",
    "Vamos focar na raspagem de dados de tabelas HTML. Esses são dados que estão em tags \\<table\\> e geralmente aparecem como tabelas no navegador. Esse tipo de tabela pode ser obtido diretamente pela biblioteca Pandas, o que reduz bastante o trabalho envolvido na raspagem. \n",
    "\n",
    "## Limpeza e Organização dos dados\n",
    "\n",
    "Uma vez que os dados foram coletados é possível que eles precisem ser limpos e organizados para que seja possível realizar a análise. Essa limpeza ou tratamento dos dados visa garantir sua integridade. Muitas vezes dados numéricos serão importados como texto e datas precisam ser reformatadas para poderem ser acessadas e processadas.\n",
    "\n",
    "Esse processo de limpeza é realizado ao mesmo tempo que o conjunto de dados é organizado. Essa organização é o que garante que o conjunto de dados contém os dados de interesse e não contém colunas duplicadas ou dados que não possam ser utilizados. \n",
    "\n",
    "O conjunto de dados tratado e organizado é o que vamos salvar e compartilhar para a realização das análises. Um conjunto de dados bem construído é valioso e devemos ter muito cuidado para não perder as horas de trabalho que passamos limpando e organizando. Geralmente o conjunto de dados final é salvo em formato CSV, JSON em tabelas XLSX ou em bancos de dados para fácil acesso e processamento posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6948772",
   "metadata": {},
   "source": [
    "#### Limpeza de dados\n",
    "\n",
    "Vamos começar tratando datas e organizando as colunas de um conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos começar estudando a própria história do Python\n",
    "# A URL a seguir contém uma tabela com informações sobre Python\n",
    "url = 'https://en.wikipedia.org/wiki/History_of_Python'\n",
    "# Vamos ler a tabela com Pandas. \n",
    "dfs = pd.read_html(url)\n",
    "# O resultado é uma lista de DataFrames.\n",
    "# Cada tabela da página é um elemento dessa lista.\n",
    "print(len(dfs)) # Podemos ver quantas tabelas foram obtidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ae396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos analisar a tabela obtida\n",
    "dados = dfs[0]\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que algumas colunas não parecem ter muitos valores válidos\n",
    "# Vamos obter um sumário dos dados com a função info()\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temos 31 elementos e 5 colunas, mas apenas 3 possuem todos os elementos\n",
    "# Como são poucos elementos, vamos visualizar o conjunto inteiro\n",
    "dados # Observe as últimas entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As últimas linhas obtidas são a legenda da tabela e precisam ser excluídas\n",
    "# A última linha corresponde a uma versão que não saiu, vamos eliminar também\n",
    "dados = dados[0:28]\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583dbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos eliminar as linhas 3, 4 e 5, que correspondem a versão unsupported\n",
    "dados = dados.drop(index=[3,4,5]) # Vamos utilizar a função drop()\n",
    "dados = dados.reset_index(drop=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de946f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos agora limpar as colunas das marcações da Wikipedia\n",
    "# Vemos que todas as colunas possuem dados entre colchetes []\n",
    "# Vamos eliminar todos esses com a função split()\n",
    "dados['Latest micro version'] = [dado.split('[')[0] for dado in dados['Latest micro version']]\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f894976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos repetir para cada coluna\n",
    "dados['Release date'] = [dado.split('[')[0] for dado in dados['Release date']]\n",
    "dados['End of full support'] = [dado.split('[')[0] for dado in dados['End of full support']]\n",
    "dados['End of security fixes'] = [dado.split('[')[0] for dado in dados['End of security fixes']]\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por fim, vamos tratar os dados de datas\n",
    "# Vamos utilizar a coluna Release Date como exemplo\n",
    "# O formato nessa coluna está aaaa-mm-dd\n",
    "# Vamos utilizar a função split() novamente separando pelo -\n",
    "# Vamos salvar o resultado como um objeto datetime\n",
    "dados['Release date'] = [datetime.datetime(int(dado.split('-')[0]),int(dado.split('-')[1]),int(dado.split('-')[2])) for dado in dados['Release date']]\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Release date'][0].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['End of full support'][0].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para organizar os dados, vamos utilizar outra variável\n",
    "dados_limpos = pd.DataFrame() # Vamos começar com um DataFrame vazio\n",
    "dados_limpos = dados[['Latest micro version','Release date']]\n",
    "dados_limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55130f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por fim, vamos salvar nossos dados\n",
    "dados_limpos.to_csv('python-versões.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c700bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos olhar outros exemplos\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_films_based_on_Marvel_Comics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba296657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marvel_site=pd.read_html(wiki,match='Box office')\n",
    "len(df_marvel_site)\n",
    "df_marvel = df_marvel_site[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um exemplo com BeautifulSoup\n",
    "\n",
    "res = requests.get(\"http://www.nationmaster.com/country-info/stats/Media/Internet-users\")\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')[0] \n",
    "df = pd.read_html(str(table))\n",
    "print(df[0].to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(table))[0]\n",
    "countries = df[\"COUNTRY\"].tolist()\n",
    "users = df[\"AMOUNT\"].tolist()\n",
    "countries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
